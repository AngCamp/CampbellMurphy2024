Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job stats:
job                   count
------------------  -------
allen_swr_detector        1
total                     1

Select jobs to execute...

[Sun May 12 23:27:15 2024]
rule allen_swr_detector:
    jobid: 0
    reason: Rules with neither input nor output files are always executed.
    priority: 3
    resources: tmpdir=/tmp

[Sun May 12 23:27:19 2024]
Error in rule allen_swr_detector:
    jobid: 0
    conda-env: /home/acampbell/NeuropixelsLFPOnRamp/DetectingSWRs/ABI_Pipeline/.snakemake/conda/ca45847e3f6350b23d084fc419a621a6_
    shell:
        
        python allen_swr_detector.py 
        --pool_size 6 
        --sdk_cache_dir /space/scratch/allen_visbehave_data 
        --output_dir . 
        --swr_output_dir testing_dir_filtered 
        --run_name final_run 
        --select_these_sessions  
        --only_brain_observatory_sessions True 
        --dont_wipe_these_sessions  
        --gamma_event_thresh 3 
        --gamma_filter_path /home/acampbell/NeuropixelsLFPOnRamp/PowerBandFilters/swr_detection_script_filters_1500Hz/frank2008_gamma_1500hz_bandpass_filter.npz 
        --theta_filter_path /home/acampbell/NeuropixelsLFPOnRamp/PowerBandFilters/swr_detection_script_filters_1500Hz/theta_1500hz_bandpass_filter.npz 
        --ripple_band_threshold 2 
        --movement_artifact_ripple_band_threshold 2 
        > 
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-05-12T232715.132002.snakemake.log
